{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GCP-Coupons-Instructions.rtf', 'train.csv.zip', 'sample_submission.csv', 'test.csv', 'train.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # CSV file I/O (e.g. pd.read_csv)\n",
    "import os # reading the input files we have access to\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "import chainer\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "import math\n",
    "from chainer import cuda, training, reporter, Variable\n",
    "from chainer.training import trainer, extensions\n",
    "from chainer import datasets\n",
    "from chainer.dataset import convert\n",
    "from chainer.dataset import iterator as iterator_module\n",
    "from chainer import optimizer as optimizer_module\n",
    "from chainer import iterators\n",
    "from chainer import optimizers\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "device = 0\n",
    "\n",
    "print(os.listdir('./input'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "key                   object\n",
       "fare_amount          float64\n",
       "pickup_datetime       object\n",
       "pickup_longitude     float64\n",
       "pickup_latitude      float64\n",
       "dropoff_longitude    float64\n",
       "dropoff_latitude     float64\n",
       "passenger_count        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df =  pd.read_csv('./input/train.csv', nrows = 10_000_000)\n",
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a dataframe, add two new features 'abs_diff_longitude' and\n",
    "# 'abs_diff_latitude' reprensenting the \"Manhattan vector\" from\n",
    "# the pickup location to the dropoff location.\n",
    "def add_travel_vector_features(df):\n",
    "    df['abs_diff_longitude'] = (df.dropoff_longitude - df.pickup_longitude).abs()\n",
    "    df['abs_diff_latitude'] = (df.dropoff_latitude - df.pickup_latitude).abs()\n",
    "    #df.pickup_datetime = pd.to_datetime(df.pickup_datetime).dt.timestamp()\n",
    "\n",
    "add_travel_vector_features(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key                    0\n",
      "fare_amount            0\n",
      "pickup_datetime        0\n",
      "pickup_longitude       0\n",
      "pickup_latitude        0\n",
      "dropoff_longitude     69\n",
      "dropoff_latitude      69\n",
      "passenger_count        0\n",
      "abs_diff_longitude    69\n",
      "abs_diff_latitude     69\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old size: 10000000\n",
      "New size: 9999931\n"
     ]
    }
   ],
   "source": [
    "print('Old size: %d' % len(train_df))\n",
    "train_df = train_df.dropna(how = 'any', axis = 'rows')\n",
    "print('New size: %d' % len(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f515379f940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plot = train_df.iloc[:2000].plot.scatter('abs_diff_longitude', 'abs_diff_latitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old size: 9999931\n",
      "New size: 9979187\n"
     ]
    }
   ],
   "source": [
    "print('Old size: %d' % len(train_df))\n",
    "train_df = train_df[(train_df.abs_diff_longitude < 5.0) & (train_df.abs_diff_latitude < 5.0)]\n",
    "print('New size: %d' % len(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9979187, 10)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_matrix(df):\n",
    "    #df.pickup_datetime = int(pd.to_datetime(df.pickup_datetime).dt.strftime('%Y%m%d%H%M'))\n",
    "    \n",
    "    return np.column_stack((df.abs_diff_longitude, df.abs_diff_latitude, df.passenger_count)).astype(np.float32)\n",
    "\n",
    "def get_output_matrix(df):\n",
    "    return np.column_stack((df.fare_amount)).astype(np.float32).transpose((1, 0))\n",
    "\n",
    "train_x = get_input_matrix(train_df)\n",
    "train_t = get_output_matrix(train_df)\n",
    "\n",
    "test_df = pd.read_csv('./input/test.csv')\n",
    "add_travel_vector_features(test_df)\n",
    "test_x = get_input_matrix(test_df)\n",
    "#print(train_x.shape, train_t.shape, test_x.shape)\n",
    "thresh_hold = int(train_x.shape[0]*0.8)\n",
    "train = datasets.TupleDataset(train_x[:thresh_hold], train_t[:thresh_hold])\n",
    "valid = datasets.TupleDataset(train_x[thresh_hold:], train_t[thresh_hold:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9979187, 3) (9979187, 1) (9914, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape, train_t.shape, test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearBlock(chainer.Chain):\n",
    "\n",
    "    def __init__(self, inp=None, mid=256, drop=False, bn = False):\n",
    "        w = chainer.initializers.HeNormal()\n",
    "        super(LinearBlock, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.fc = L.Linear(inp, mid, initialW=w)\n",
    "            self.bnorm = L.BatchNormalization(mid)\n",
    "        self.drop = drop\n",
    "        self.bn = bn\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h = self.fc(x)\n",
    "        if self.bn:\n",
    "            h = self.bnorm(h)\n",
    "        h = F.relu(h)\n",
    "        if self.drop:\n",
    "            h = F.dropout(h)\n",
    "        return h\n",
    "    \n",
    "class EnsembleNet(chainer.Chain):\n",
    "    def __init__(self, mid):\n",
    "        super(EnsembleNet, self).__init__()\n",
    "        w = chainer.initializers.HeNormal()\n",
    "        \n",
    "        with self.init_scope():\n",
    "            self.l1 = LinearBlock(mid = mid, bn = True)\n",
    "            self.l2 = LinearBlock(mid = mid*2, bn = True)\n",
    "            \n",
    "            self.last = L.Linear(None, 1, initialW=w)\n",
    "            \n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h = self.last(self.l2(self.l1(x)))\n",
    "        #h = F.concat((h1, h2, h3, h4), axis = -1)\n",
    "        #h = h1\n",
    "        #h = F.mean(h, axis=-1, keepdims=True)\n",
    "        #h  = self.concat(F.relu(h))\n",
    "        return h\n",
    "    \n",
    "#     def predict(self, x):\n",
    "#         with chainer.using_config('train', False), chainer.using_config('enable_backprop', False):\n",
    "#             y_pred = F.mean(self.forward(x), axis=-1, keepdims=True)\n",
    "#         return y_pred\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chainer\n",
    "import numpy as np\n",
    "import six\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer import training, cuda, reporter\n",
    "from chainer.dataset import convert\n",
    "from chainer.dataset import iterator as iterator_module\n",
    "\n",
    "class EnsembleUpdater(training.StandardUpdater):\n",
    "    def __init__(self, iterator, net_dict, opt,\n",
    "        converter=convert.concat_examples, device=0):\n",
    "        if isinstance(iterator, iterator_module.Iterator):\n",
    "            iterator = {'main': iterator}\n",
    "        self._iterators = iterator\n",
    "        self.net_dict = net_dict\n",
    "        self._optimizers = opt\n",
    "        self.converter = converter\n",
    "        self.device = device\n",
    "        self.iteration = 0\n",
    "\n",
    "    def update_core(self):\n",
    "        #print(self.iteration)\n",
    "        iterator = self._iterators['main'].next()\n",
    "        #入力データ\n",
    "        input = self.converter(iterator, self.device)\n",
    "        xp = np if int(self.device) == -1 else cuda.cupy\n",
    "        x_batch = xp.array(input[0], dtype=np.float32) #入力データ\n",
    "        t_batch = xp.array(input[1], dtype=np.float32) #教師データ\n",
    "        #loss\n",
    "        loss_dic = {}\n",
    "        for i, net in enumerate(self.net_dict.values()):\n",
    "            loss = F.mean_squared_error(net(x_batch), t_batch)\n",
    "            loss_dic[str(i)] = loss\n",
    "            \n",
    "        #計算開始\n",
    "        for name, optimizer in six.iteritems(self._optimizers):\n",
    "            optimizer.target.cleargrads()\n",
    "            \n",
    "        for name, loss in six.iteritems(loss_dic):\n",
    "            loss.backward()\n",
    "\n",
    "        for name, optimizer in six.iteritems(self._optimizers):\n",
    "            optimizer.update()\n",
    "        report_dict = {}\n",
    "        for i, loss in enumerate(loss_dic.values()):\n",
    "            report_dict['main/loss'+str(i)] =  loss\n",
    "        reporter.report(report_dict)\n",
    "\n",
    "        \n",
    "import chainer\n",
    "import copy\n",
    "import numpy as np\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer import training, cuda, reporter\n",
    "from chainer.training import extensions\n",
    "from chainer.dataset import convert\n",
    "from chainer.dataset import iterator as iterator_module\n",
    "\n",
    "class  EnsembleEvaluator(extensions.Evaluator):\n",
    "    def __init__(self, iterator, net_dict,\n",
    "        converter=convert.concat_examples, device=0, eval_hook=None,\n",
    "        eval_func=None):\n",
    "        if isinstance(iterator, iterator_module.Iterator):\n",
    "            iterator = {'main': iterator}\n",
    "        self._iterators = iterator\n",
    "        self._targets = net_dict\n",
    "        self.converter = converter\n",
    "        self.device = device\n",
    "        self.eval_hook = eval_hook\n",
    "\n",
    "    def evaluate(self):\n",
    "        iterator = self._iterators['main']\n",
    "        #入力データ\n",
    "        xp = np if int(self.device) == -1 else cuda.cupy\n",
    "        it = copy.copy(iterator)\n",
    "        summary = reporter.DictSummary()\n",
    "        for batch in it:\n",
    "            observation = {}\n",
    "            with reporter.report_scope(observation):\n",
    "                input = self.converter(batch, self.device)\n",
    "                x_batch = xp.array(input[0], dtype=np.float32) #入力データ\n",
    "                t_batch = xp.array(input[1], dtype=np.float32) #教師データ\n",
    "                #loss\n",
    "                loss = 0\n",
    "                #計算開始\n",
    "                with chainer.using_config('train', False), chainer.using_config('enable_backprop', False):\n",
    "                    for i, net in enumerate(self._targets.values()):\n",
    "                        loss = loss + F.mean_squared_error(net(x_batch), t_batch)\n",
    "                    loss = loss/len(self._targets.values())\n",
    "                observation['val/main/loss'] = loss\n",
    "            summary.add(observation)\n",
    "        return summary.compute_mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_iter = iterators.SerialIterator(train, batch_size)\n",
    "valid_iter  = iterators.SerialIterator(valid, batch_size, repeat=False, shuffle=False)\n",
    "test_iter = iterators.SerialIterator(test_x, batch_size, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "net1 = EnsembleNet(mid = 8)\n",
    "net2 = EnsembleNet(mid = 16)\n",
    "net3 = EnsembleNet(mid = 32)\n",
    "net4 = EnsembleNet(mid = 64)\n",
    "net_dict = {'0': net1, '1': net2, '2': net3, '3': net4}\n",
    "optimizer_dict= {}\n",
    "for i, net in enumerate(net_dict.values()):\n",
    "        if device >= 0:\n",
    "            net.to_gpu(device)\n",
    "        optimizer = optimizers.Adam(alpha=0.0002, beta1=0.9, beta2=0.999).setup(net)\n",
    "        optimizer.add_hook(chainer.optimizer.WeightDecay(0.0001))\n",
    "        optimizer_dict[str(i)] = optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "updater = EnsembleUpdater(train_iter, net_dict, optimizer_dict, device=device)\n",
    "max_iteration = 10000\n",
    "trainer = training.Trainer(updater, (max_iteration, 'iteration'), out='results')\n",
    "trainer.extend(extensions.LogReport(trigger=(100, 'iteration')))\n",
    "print_report_list = []\n",
    "for i, net in enumerate(net_dict.values()):\n",
    "    trainer.extend(extensions.snapshot_object(net, filename='net'+str(i)+'_iteration-{.updater.iteration}'), trigger=(1000,'iteration'))\n",
    "    print_report_list.append('main/loss'+str(i))\n",
    "trainer.extend(EnsembleEvaluator(valid_iter, net_dict, device=device), name='val', trigger=(100,'iteration'))\n",
    "trainer.extend(extensions.PrintReport(['iteration', print_report_list[0], print_report_list[1], print_report_list[2], print_report_list[3],  'val/main/loss', 'elapsed_time']))\n",
    "trainer.extend(extensions.PlotReport([print_report_list[0], print_report_list[1], print_report_list[2], print_report_list[3], 'val/main/loss'], x_key='iteration', file_name='loss.png'))\n",
    "#trainer.extend(extensions.dump_graph(print_report_list[0], print_report_list[1], print_report_list[2], print_report_list[3],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_net1 = EnsembleNet(mid = 8)\n",
    "infer_net2 = EnsembleNet(mid = 16)\n",
    "infer_net3 = EnsembleNet(mid = 32)\n",
    "infer_net4 = EnsembleNet(mid = 64)\n",
    "infer_net_dict = {'0': net1, '1': net2, '2': net3, '3': net4}\n",
    "from chainer import serializers\n",
    "for i, infer_net in enumerate(infer_net_dict.values()):\n",
    "    serializers.load_npz('results/'+'net'+str(i)+'_iteration-10000', infer_net, path='')\n",
    "    if device >= 0:\n",
    "        infer_net.to_gpu(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_x = test_x\n",
    "t_x = infer_net.xp.asarray(t_x)\n",
    "y_pred = 0\n",
    "with chainer.using_config('train', False), chainer.using_config('enable_backprop', False):\n",
    "    for i, infer_net in enumerate(infer_net_dict.values()):\n",
    "        y_pred = y_pred + infer_net(t_x).array\n",
    "    y = y_pred / len(infer_net_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = chainer.cuda.to_cpu(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred.reshape(-1)\n",
    "submission = pd.DataFrame(\n",
    "    {'key': test_df.key, 'fare_amount': y_pred},\n",
    "    columns = ['key', 'fare_amount'])\n",
    "submission.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
